{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0. Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports (uncomment / add more as needed)\n",
    "\n",
    "#import re\n",
    "#import ast\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "#import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/notebooks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store path to notebook\n",
    "PWD = !pwd\n",
    "PWD = PWD[0]\n",
    "PWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "app_name = \"final_proj_notebook\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General Parameters / Global Options\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.options.display.float_format = '{:.4f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Data Preparation\n",
    "Load, parse, sample, normalize, and deal with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column Labels\n",
    "colLabels = ['Label', 'I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', \n",
    "             'I9', 'I10', 'I11', 'I12', 'I13', 'C1', 'C2', 'C3', 'C4', \n",
    "             'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', \n",
    "             'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21', \n",
    "             'C22', 'C23', 'C24', 'C25', 'C26']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "trainRDD = sc.textFile('data/train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "def convertToInt(rowIn):\n",
    "    output = []\n",
    "    for j, item in enumerate(rowIn):\n",
    "        if item == '':\n",
    "            output.append(np.nan)\n",
    "        else:\n",
    "            if j < 14:\n",
    "                output.append(int(item)) \n",
    "            else:\n",
    "                output.append(item)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get sample, to make for faster testing\n",
    "#Note: .sample produces an inconsistent number of rows. It's similar, but not exaxtly the same every time.\n",
    "\n",
    "runSample = True\n",
    "#Usual sample: 0.0025\n",
    "if runSample:\n",
    "    trainRDD = trainRDD.sample(False, 0.0025)\n",
    "\n",
    "trainSampleRDD = trainRDD \\\n",
    "    .map(lambda x: (x.split('\\t'))) \\\n",
    "    .map(convertToInt) \\\n",
    "    .map(lambda x: (x[1:14], x[0])) \\\n",
    "    .cache()\n",
    "\n",
    "#Inspect. Should be ~115K rows at 0.0025, in form (I1-I13, Label)\n",
    "# sampleCount = trainSampleRDD.count()\n",
    "# print('Row Count:', sampleCount)\n",
    "# print('Sample:', trainSampleRDD.take(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos Count: 11745438\n",
      "Neg Count: 34095179\n"
     ]
    }
   ],
   "source": [
    "#Balance Classes\n",
    "#Don't forget to split train/test first!\n",
    "\n",
    "#Note it stacks the two RDDs, so it's all negative first, then all positive\n",
    "def balanceRDD(RDDIn, check=False):\n",
    "\n",
    "    #Count classes (filter)\n",
    "    posClassRDD = RDDIn.filter(lambda x: x[1]==1)\n",
    "    posCount = posClassRDD.count()\n",
    "    negCount = RDDIn.count() - posCount\n",
    "    print('Pos Count:', posCount)\n",
    "    print('Neg Count:', negCount)\n",
    "\n",
    "    negClassRDD = trainSampleRDD.filter(lambda x: x[1]==0).sample(False, posCount/negCount)\n",
    "    outputRDD = negClassRDD.union(posClassRDD)\n",
    "\n",
    "    #Math check. Set to False for full data as this is expensive\n",
    "    if check:\n",
    "        print('Check')\n",
    "        print('Pos Count:', outputRDD.filter(lambda x: x[1]==1).count())\n",
    "        print('Neg Count:', outputRDD.filter(lambda x: x[1]==0).count())\n",
    "        \n",
    "    return outputRDD\n",
    "        \n",
    "trainSampleBalRDD = balanceRDD(trainSampleRDD, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(dataRDD):\n",
    "    \"\"\"\n",
    "    Scale and center data round mean of each feature.\n",
    "    Ignores np.nan elements\n",
    "    Args:\n",
    "        dataRDD - records are tuples of (features_array, y)\n",
    "    Returns:\n",
    "        normedRDD - records are tuples of (features_array, y)\n",
    "    \"\"\"\n",
    "    \n",
    "    featureMeans, featureStdev = [], []\n",
    "    for i, _ in enumerate(dataRDD.take(1)[0][0]):\n",
    "        values = dataRDD \\\n",
    "            .map(lambda x: x[0][i]) \\\n",
    "            .collect()\n",
    "        featureMeans.append(np.nanmean(values))\n",
    "        featureStdev.append(np.nanstd(values))\n",
    "        \n",
    "    featureMeansB = sc.broadcast(np.array(featureMeans))\n",
    "    featureStdevB = sc.broadcast(np.array(featureStdev))\n",
    "    \n",
    "    print('Means:', featureMeansB.value)\n",
    "    print('StDevs:', featureStdevB.value)\n",
    "    \n",
    "    normedRDD = dataRDD.map(lambda x: ( (x[0] - featureMeansB.value) / featureStdevB.value, x[1]) ) \\\n",
    "        .map(lambda x: (tuple(x[0]), x[1]))\n",
    "    \n",
    "    return normedRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleanRDD Sample: [((2, 0, 1, 14, 767, 89, 4, 2, 245, 1, 3, 3, 45), 0), ((3, -1, 0, 0, 2, 0, 3, 0, 0, 1, 1, 0, 0), 0), ((0, 1, 2, 0, 3168, 0, 0, 1, 2, 0, 0, 0, 0), 0), ((0, 44, 4, 8, 19010, 249, 28, 31, 141, 0, 1, 0, 8), 0)]\n",
      "Means: [    2.33121935   115.55313147    23.03454163     5.47585998\n",
      " 15125.43013278    79.53255721    18.70428372    12.25743996\n",
      "   104.45763228     0.40070149     3.06701879     0.30856155\n",
      "     5.8156455 ]\n",
      "StDevs: [    7.93134509   417.28454322   436.52355297     8.0678134\n",
      " 60917.50009471   303.08252102    70.96073056    15.76858304\n",
      "   221.18996264     0.63977892     5.67636872     3.14805603\n",
      "    13.16015133]\n",
      "Sample: [((-0.0417608040711868, -0.27691687445267055, -0.05047732585802495, 1.0565613747159377, -0.2357028786548276, 0.03123717844460078, -0.20721719758659723, -0.6504985221800808, 0.6353921581342568, 0.9367274943395123, -0.011806630747232877, 0.854952522903319, 2.9775002964372317), 0), ((0.0843212146581048, -0.2793133207535268, -0.052768152992557334, -0.678729131645782, -0.2482608463785624, -0.26241222007944603, -0.2213094989501405, -0.7773330002695543, -0.4722530400128552, 0.9367274943395123, -0.36414456019106517, -0.09801653827120677, -0.4419132696193536), 0), ((-0.29392484152977, -0.27452042815181427, -0.048186498723492566, -0.678729131645782, -0.1962889172107919, -0.26241222007944603, -0.26358640304077025, -0.7139157612248175, -0.46321103839532773, -0.6263124318182279, -0.5403135249129813, -0.09801653827120677, -0.4419132696193536), 0), ((-0.29392484152977, -0.17147323721499594, -0.043604844454427805, 0.31286544341805783, 0.06376771635706048, 0.559146209499067, 0.1309980351384409, 1.1886014101172855, 0.16520807402282967, -0.6263124318182279, -0.36414456019106517, -0.09801653827120677, 0.1659824754573726), 0)]\n"
     ]
    }
   ],
   "source": [
    "#Assigning np.nan values\n",
    "\n",
    "#DoubleMax strategy might blow up gradient descent ... maybe we should normalize after ...\n",
    "\n",
    "#Helper Function\n",
    "def setNanTo(rowIn, maxValsIn, nanReplacementValue='zero'):\n",
    "    output = []\n",
    "    for i, item in enumerate(rowIn[0]):\n",
    "        if np.isnan(item):\n",
    "            if nanReplacementValue == 'doubleMax':\n",
    "                output.append(maxValsIn[i] * 2)\n",
    "            else:\n",
    "                output.append(0)\n",
    "        else:\n",
    "            output.append(item)\n",
    "    return (tuple(output), rowIn[1])\n",
    "\n",
    "#Get Max Values ... MEMORY ERROR\n",
    "maxVals = None\n",
    "# maxVals = np.nanmax( trainSampleBalRDD.map(lambda x: x[0]).collect(), axis=0 )\n",
    "# print('Max Values:', maxVals)\n",
    "\n",
    "#Handle nan's\n",
    "cleanRDD = trainSampleBalRDD.map(lambda x: setNanTo(x, maxVals, 'zero')).cache()\n",
    "print('cleanRDD Sample:', cleanRDD.take(4))\n",
    "\n",
    "#Normalize\n",
    "normedCleanRDD = normalize(cleanRDD).cache()\n",
    "#print('Row Count:', normedCleanRDD.count())\n",
    "print('Sample:', normedCleanRDD.take(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify normalization (should see all means = 0 and stdevs = 1)\n",
    "#An expensive test, but it works\n",
    "#Comment out for 'production' code\n",
    "\n",
    "# normedCleanRDD = normalize(normedCleanRDD).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Logistic Regression\n",
    "\n",
    "Now we have our data in good shape. Let's implement logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test ... ultimately didn't use\n",
    "def sigmoid_grad(x):\n",
    "    ex = np.exp(-x)\n",
    "    y = ex / (1 + ex)**2\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23500371, 0.24026075, 0.0000454 , 0.19661193, 0.25      ,\n",
       "       0.19661193, 0.0000454 ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test ... ultimately didn't use\n",
    "sigmoid_grad(np.array([.5, .4, -10, -1, 0, 1, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not needed if nan uses 'zero' option (default)\n",
    "\n",
    "# print('Sample:', normedCleanRDD.take(4))\n",
    "# normedCleanRDD = normalize(normedCleanRDD).cache()\n",
    "# print('Sample:', normedCleanRDD.take(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference from HW4\n",
    "def OLSLoss(dataRDD, W):\n",
    "    \"\"\"\n",
    "    Compute mean squared error.\n",
    "    Args:\n",
    "        dataRDD - each record is a tuple of (features_array, y)\n",
    "        W       - (array) model coefficients with bias at index 0\n",
    "    \"\"\"\n",
    "    augmentedData = dataRDD.map(lambda x: (np.append([1.0], x[0]), x[1]))\n",
    "    ################## YOUR CODE HERE ##################    \n",
    "    loss = augmentedData.map(lambda x: ( (W.dot(x[0]) - x[1])**2) ).mean()\n",
    "    ################## (END) YOUR CODE ##################\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(features, weightsIn):\n",
    "    return expit(np.dot(features, weightsIn))\n",
    "\n",
    "def logRegLoss(dataRDD, W):\n",
    "    \"\"\"\n",
    "    Compute mean squared error.\n",
    "    Args:\n",
    "        dataRDD - each record is a tuple of (features_array, y)\n",
    "        W       - (array) model coefficients with bias at index 0\n",
    "    \"\"\"\n",
    "    \n",
    "    def calcLoss(rowIn, WIn):\n",
    "        if rowIn[1] == 0:\n",
    "            output = -np.log(1-min(0.999999999999, predict(rowIn[0], WIn) ))\n",
    "        else:\n",
    "            output = -np.log(max(0.0000000000001, predict(rowIn[0], WIn)  ))\n",
    "            \n",
    "        return output\n",
    "    \n",
    "    #Add bias term\n",
    "    augmentedData = dataRDD.map(lambda x: (np.append([1.0], x[0]), x[1]))\n",
    "    \n",
    "    logLoss = augmentedData.map(lambda x: calcLoss(x, W) ).mean()\n",
    "    \n",
    "    #Alternate strategy\n",
    "    #logLoss = augmentedData.map(lambda x: ( (-x[1]*np.log(expit(W.dot(x[0])))) - ( (1-x[1]) * np.log(1-expit(W.dot(x[0]) ) ) ))).mean()\n",
    "    \n",
    "    #Form, for reference\n",
    "    #(-y * np.log(expit(pred))) - ( (1-y)*np.log(1-expit(pred)) )\n",
    "    \n",
    "    ### BUILD TOY MODEL TO ENSURE PROPER LOSS IS CALCULATED ###\n",
    "    \n",
    "    return logLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model OLS loss: 0.4999600089474395\n",
      "Baseline model LogReg loss: 0.6931471805599452\n"
     ]
    }
   ],
   "source": [
    "#Baseline model  ### NOTE VALUES ARE HARDCODED AND WILL NEED REPLACING! ###\n",
    "wInit = np.append(0.0, np.zeros(13))\n",
    "\n",
    "assert len(wInit) == len(normedCleanRDD.take(1)[0][0]) + 1, \"Double check model dimensions\"\n",
    "\n",
    "print('Baseline model OLS loss:', OLSLoss(normedCleanRDD, wInit))\n",
    "print('Baseline model LogReg loss:', logRegLoss(normedCleanRDD, wInit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateWeights(dataRDD, weightsIn, lrIn):\n",
    "    \n",
    "    augmentedData = dataRDD.map(lambda x: (np.append([1.0], x[0]), x[1])).cache()\n",
    "    #grad = augmentedData.map(lambda x: np.dot(expit(np.dot(weightsIn, x[0])), x[0] ) - x[1] ).mean()\n",
    "    grad = augmentedData.map(lambda x:  np.dot( x[0].T, predict(x[0], weightsIn) - x[1] )  ).mean()\n",
    "    newWeights = weightsIn - (lrIn * grad)\n",
    "    \n",
    "    return newWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Baseline model LogReg loss: 0.6931471805599452\n",
      "---------------\n",
      "ITERATION 0\n",
      "weights: [-0.00002     0.02699881  0.01194005  0.00227665 -0.01651274 -0.02464195\n",
      " -0.01798857  0.02222214 -0.00834909  0.00671709  0.05079834  0.04086097\n",
      "  0.01241957 -0.02422426]\n",
      "LogLoss: 0.6796589042162738\n",
      "---------------\n",
      "ITERATION 1\n",
      "weights: [ 0.00001134  0.04505797  0.02141821  0.00436531 -0.03080649 -0.04460891\n",
      " -0.0326381   0.03529931 -0.01673724  0.01031426  0.09065515  0.07090442\n",
      "  0.02178616 -0.0448825 ]\n",
      "LogLoss: 0.671574086589629\n",
      "---------------\n",
      "ITERATION 2\n",
      "weights: [ 0.00019185  0.05780365  0.02905708  0.00629901 -0.04299535 -0.06114957\n",
      " -0.04489619  0.04348473 -0.02490551  0.01225739  0.12290016  0.09426454\n",
      "  0.0292497  -0.06288505]\n",
      "LogLoss: 0.666288379370978\n",
      "---------------\n",
      "ITERATION 3\n",
      "weights: [ 0.00053882  0.06703318  0.03527974  0.00810192 -0.05325427 -0.07512111\n",
      " -0.05531199  0.04867641 -0.03260586  0.01331023  0.14957019  0.11317853\n",
      "  0.03542601 -0.07866473]\n",
      "LogLoss: 0.6626456634709283\n",
      "---------------\n",
      "ITERATION 4\n",
      "weights: [ 0.0010287   0.07376667  0.0403881   0.00978986 -0.06181005 -0.08710875\n",
      " -0.06426402  0.05185635 -0.039751    0.01386985  0.17197897  0.12893209\n",
      "  0.04067231 -0.09257931]\n",
      "LogLoss: 0.6600432188049623\n",
      "---------------\n",
      "ITERATION 5\n",
      "weights: [ 0.00162625  0.07864875  0.04460603  0.01137458 -0.06888883 -0.09752361\n",
      " -0.07202785  0.05360266 -0.04632893  0.0141541   0.1910307   0.1423317\n",
      "  0.04521453 -0.1049233 ]\n",
      "LogLoss: 0.6581329044242696\n",
      "---------------\n",
      "ITERATION 6\n",
      "weights: [ 0.00229644  0.0821168   0.0481042   0.01286552 -0.07469702 -0.10666367\n",
      " -0.07881119  0.05428634 -0.0523621   0.01428719  0.20737833  0.15391752\n",
      "  0.04920519 -0.11593843]\n",
      "LogLoss: 0.6566990749251784\n",
      "---------------\n",
      "ITERATION 7\n",
      "weights: [ 0.00300872  0.08448286  0.05101539  0.01427067 -0.07941609 -0.11475119\n",
      " -0.08477472  0.05416041 -0.05788778  0.01434167  0.22151055  0.1640695\n",
      "  0.05275234 -0.12582352]\n",
      "LogLoss: 0.655602065223773\n",
      "---------------\n",
      "ITERATION 8\n",
      "weights: [ 0.00373815  0.08597793  0.05344457  0.01559697 -0.08320285 -0.12195624\n",
      " -0.09004529  0.05340535 -0.06294839  0.01436026  0.23380327  0.17306508\n",
      "  0.05593543 -0.13474278]\n",
      "LogLoss: 0.6547481482164474\n",
      "---------------\n",
      "ITERATION 9\n",
      "weights: [ 0.00446516  0.0867779   0.05547575  0.01685054 -0.08619175 -0.12841183\n",
      " -0.0947248   0.05215443 -0.06758668  0.01436799  0.24455205  0.18111294\n",
      "  0.05881464 -0.14283259]\n",
      "LogLoss: 0.6540726755648306\n"
     ]
    }
   ],
   "source": [
    "#Execute!\n",
    "\n",
    "#Don't forget to un-hardcode weights\n",
    "lr = 0.5\n",
    "weights = np.append(0.0, np.zeros(13))\n",
    "numIter = 10\n",
    "print('weights:', weights)\n",
    "print('Baseline model LogReg loss:', logRegLoss(normedCleanRDD, weights))\n",
    "lossPerIter = []\n",
    "for i in range(numIter):\n",
    "    print('---------------')\n",
    "    print('ITERATION', i)\n",
    "    weights = updateWeights(normedCleanRDD, weights, lr)\n",
    "    print('weights:', weights)\n",
    "    lossPerIter.append((i+1, logRegLoss(normedCleanRDD, weights)))\n",
    "    print('LogLoss:', lossPerIter[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.6796589 ],\n",
       "       [ 2.        ,  0.67157409],\n",
       "       [ 3.        ,  0.66628838],\n",
       "       [ 4.        ,  0.66264566],\n",
       "       [ 5.        ,  0.66004322],\n",
       "       [ 6.        ,  0.6581329 ],\n",
       "       [ 7.        ,  0.65669907],\n",
       "       [ 8.        ,  0.65560207],\n",
       "       [ 9.        ,  0.65474815],\n",
       "       [10.        ,  0.65407268]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(lossPerIter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Log Loss')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.lineplot(x=np.array(lossPerIter)[:,0], y=np.array(lossPerIter)[:,1])\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Log Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4539054332618361 -0.7898663994176731\n",
      "0.5903294361735367 -0.5270745315150593\n",
      "0.47643273340390185 -0.7414287339455792\n",
      "0.3919492590619146 -0.9366228887384909\n",
      "0.461572368800826 -0.7731164251968337\n",
      "0.44095878117518983 -0.818803874626503\n",
      "0.42975901313605797 -0.8445306619639878\n",
      "0.45040945173713 -0.7975982171700711\n",
      "0.43866498679525245 -0.8240192852664221\n",
      "0.467011285299529 -0.7614018560816046\n",
      "0.575193494362686 -0.5530487828571228\n",
      "0.6834819081472541 -0.3805550925945639\n",
      "0.5557197609163893 -0.5874911389247219\n",
      "0.46617514070769733 -0.7631938770375271\n",
      "0.5990500157110523 -0.5124101856696167\n",
      "0.4333364720036787 -0.8362407811414373\n",
      "0.38187039377610293 -0.9626740112537967\n",
      "0.5334148778844054 -0.6284557750765212\n",
      "0.46449668571019403 -0.766800855930892\n"
     ]
    }
   ],
   "source": [
    "#Test Individual Point\n",
    "for i in range(1,20):\n",
    "    sig = expit(np.dot(np.append([1.0], normedCleanRDD.take(i)[i-1][0]), weights))\n",
    "    #sig = expit(np.dot(np.append([1.0], np.zeros(13)), weights))\n",
    "    ans = np.log(sig)\n",
    "    print(sig, ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.60517019, -2.30258509,  0.        ,  2.30258509,  4.60517019])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log([0.01, 0.1, 1, 10, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calc Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00446516,  0.0867779 ,  0.05547575,  0.01685054, -0.08619175,\n",
       "       -0.12841183, -0.0947248 ,  0.05215443, -0.06758668,  0.01436799,\n",
       "        0.24455205,  0.18111294,  0.05881464, -0.14283259])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Interesting Results:\n",
    "lr = 0.3\n",
    "numIter = 10\n",
    "array([-0.21280418,  0.36476062,  0.6365257 ,  0.4934485 ,  0.38789249,\n",
    "        0.55882766,  0.3934802 ,  0.4926317 ,  0.76201547,  0.49301356,\n",
    "        0.36908828,  0.50579076,  0.53993099,  0.38659237])\n",
    "\t\t\n",
    "lr = 0.1\n",
    "numIter = 10\n",
    "array([0.18464049, 0.18501116, 0.23620699, 0.21078129, 0.19009155,\n",
    "       0.21532381, 0.18811173, 0.1955444 , 0.25281205, 0.19560761,\n",
    "       0.18576492, 0.19786945, 0.21667081, 0.18986972])\n",
    "\n",
    "lr = 0.1\n",
    "numIter = 30\n",
    "array([-0.1993091 ,  0.35552302,  0.62923536,  0.48420718,  0.377642  ,\n",
    "        0.55082399,  0.38288815,  0.48192053,  0.76074854,  0.48231122,\n",
    "        0.3599494 ,  0.4954125 ,  0.53131016,  0.37630401])\n",
    "        \n",
    "Notice 1. and 3. are nearly the same.\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos Count: 11745438\n",
      "Neg Count: 11747317\n"
     ]
    }
   ],
   "source": [
    "#Verify Class Counts\n",
    "print('Pos Count:', normedCleanRDD.filter(lambda x: x[1]==1).count())\n",
    "print('Neg Count:', normedCleanRDD.filter(lambda x: x[1]==0).count())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-36e676a2c62c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#weightData = np.append(1.0, np.zeros(13))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mweightData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0maccData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormedCleanRDD\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweightData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'weights' is not defined"
     ]
    }
   ],
   "source": [
    "#Accuracy, Improved\n",
    "numRows = 1000\n",
    "#rowCount = normedCleanRDD.count()\n",
    "\n",
    "#weightData = np.append(1.0, np.zeros(13))\n",
    "weightData = weights\n",
    "\n",
    "accData = normedCleanRDD \\\n",
    "    .map(lambda x: [np.round(predict(np.append([1.0], x[0]), weightData)), x[1] ] ) \\\n",
    "    .collect()\n",
    "\n",
    "y_pred = np.array(accData)[:,0]\n",
    "y_true = np.array(accData)[:,1]\n",
    "print('Log Loss:', lossPerIter[-1][1])\n",
    "print('Accuracy:', accuracy_score(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-4255932177f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_true' is not defined"
     ]
    }
   ],
   "source": [
    "sum(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.array(accData))\n",
    "print(np.sum(np.array(accData), axis=0))\n",
    "sum(np.array(accData)[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:  [ 731.05857863 1000.            0.          731.05857863]\n",
      "Accuracy:  0.0\n",
      "Output:  [ 622.4593312 1000.           0.         622.4593312]\n",
      "Accuracy:  0.0\n",
      "Output:  [500.   0.   0. 500.]\n",
      "Accuracy:  1.0\n",
      "Output:  [457.27003494 259.           0.         457.27003494]\n",
      "Accuracy:  0.741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Absolute Loss (crude)\n",
    "numRows = 1000\n",
    "rowCount = normedCleanRDD.count()\n",
    "accData = normedCleanRDD.map(lambda x:  (predict(x0,weights), x[1]) )\n",
    "\n",
    "X = normedCleanRDD.map(lambda x: x[0]).take(numRows)\n",
    "Y = normedCleanRDD.map(lambda x: x[1]).take(numRows)\n",
    "\n",
    "def calcAcc(numRowsIn, XIn, YIn, WIn):\n",
    "    result = []\n",
    "\n",
    "    for i in range(numRowsIn):\n",
    "        x = expit(np.dot(WIn, np.append([1.0],  XIn[i]  )))\n",
    "        y = YIn[i]\n",
    "        result.append((x, np.round(x), y, abs(y-x)))\n",
    "    print('Output: ', np.sum(result, axis=0))\n",
    "    print('Accuracy: ', sum(1-abs(np.array(result)[:,1] - np.array(result)[:,2])) / numRowsIn  )\n",
    "    \n",
    "    return result\n",
    "    \n",
    "calcAcc(numRows, X, Y, np.append(1.0, np.zeros(13)))\n",
    "calcAcc(numRows, X, Y, np.append(0.5, np.zeros(13)))\n",
    "calcAcc(numRows, X, Y, np.append(0.0, np.zeros(13)))\n",
    "calcAcc(numRows, X, Y, weights)\n",
    ";\n",
    "#(sum of softmax predicted values (y_hat), sum of predictions (y_hat), \n",
    "#sum of actual values (y), sum of absolute difference between y_hat_soft and y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell above:  (sum of softmax predicted values (x), sum of actual values (y), sum of absolute difference between the two)\n",
    "#Again, this is crude, but it gives a ballpark until I can fix Log Loss calc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Fixing Log Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.4206316304584733\n",
      "1 0.2682006500041653\n",
      "2 0.012829786502224893\n",
      "3 0.012829786502224893\n",
      "4 0.046827047318640146\n",
      "5 0.30912449124842406\n",
      "6 -4.256180974804324\n",
      "7 0.01649850120472889\n",
      "8 0.1718220771705769\n",
      "9 0.028280914115596276\n",
      "10 2.226593924996708\n",
      "11 1.3083214266560457\n",
      "12 -0.007519957978612399\n",
      "13 1.5273634006986285\n",
      "14 4.6840027089684675\n",
      "15 0.020910051369523633\n",
      "16 -1.6966498487475994\n",
      "17 -0.2444408399208692\n",
      "18 -0.450988788887679\n",
      "19 0.09057952356305739\n",
      "20 0.09751333061097117\n",
      "21 3.358644798610478\n",
      "22 0.09701840783660683\n",
      "23 0.35284565204830054\n",
      "24 6.495830180822665\n",
      "25 0.3347345939587952\n",
      "26 -0.010729634533885996\n",
      "27 0.18232224805538524\n",
      "28 0.11864626281942298\n",
      "29 -0.08593079050352137\n",
      "30 0.03901413456016986\n",
      "31 0.023740068115834182\n",
      "32 2.7048881197430834\n",
      "33 6.210141171901144\n",
      "34 0.8783983110386692\n",
      "35 -2.241323806428353\n",
      "36 0.05713989043160666\n",
      "37 0.04912253155525332\n",
      "38 4.597090912703127\n",
      "39 0.260575531746296\n",
      "40 -3.269790510000654\n",
      "41 -4.279982089848307\n",
      "42 0.023207568261676328\n",
      "43 0.017193306435268164\n",
      "44 0.11852729536071915\n",
      "45 2.84311021412036\n",
      "46 0.04780204943218941\n",
      "47 0.024449865491611374\n",
      "48 -1.712077433442368\n",
      "49 6.587862189828434\n"
     ]
    }
   ],
   "source": [
    "for i, rowIn in enumerate(normedCleanRDD.take(50)):\n",
    "    if i == i:\n",
    "#         print(np.append([1.0], rowIn[0]), weights)\n",
    "#         print('label:', rowIn[1])\n",
    "\n",
    "        if rowIn[1] == 0:\n",
    "            output = -np.log(1-min(0.999999, expit(weights.dot(np.append([1.0], rowIn[0])))))\n",
    "            #output = weights.dot(np.append([1.0], rowIn[0]))  #OKAY\n",
    "            #output = 1-min(0.999, expit(weights.dot(np.append([1.0], rowIn[0]))))\n",
    "        else:\n",
    "            output = np.log(expit(weights.dot(np.append([1.0], rowIn[0]))))\n",
    "        print(i, output)\n",
    "        #print(rowIn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: [0.         0.         0.         0.         0.         0.0000454\n",
      " 0.5        0.73105858 0.95257413 0.99330715 0.9999546  1.\n",
      " 1.         1.        ]\n",
      "[  0.           0.           0.           0.           0.\n",
      "  -0.0000454   -0.69314718  -1.31326169  -3.04858735  -5.00671535\n",
      " -10.0000454  -19.99999997         -inf         -inf]\n",
      "[         -inf -500.         -200.         -100.          -50.\n",
      "  -10.0000454    -0.69314718   -0.31326169   -0.04858735   -0.00671535\n",
      "   -0.0000454    -0.            0.            0.        ]\n",
      "0.0 0.0 0.0\n",
      "7.124576406741285e-218 0.0 0.0\n",
      "1.3838965267367376e-87 0.0 0.0\n",
      "3.7200759760208356e-44 0.0 0.0\n",
      "1.928749847963918e-22 0.0 0.0\n",
      "4.5397868702434395e-05 -4.539889921682063e-05 -4.539889921682063e-05\n",
      "0.5 -0.6931471805599453 -0.6931471805599453\n",
      "0.7310585786300049 -1.3132616875182228 -1.3132616875182228\n",
      "0.9525741268224334 -3.048587351573745 -3.048587351573745\n",
      "0.9933071490757153 -5.006715348489137 -5.006715348489137\n",
      "0.9999546021312976 -10.000045398900186 -10.000045398900186\n",
      "0.9999999979388463 -19.999999966169824 -19.999999966169824\n",
      "0.999999999 -inf -20.723265865228342\n",
      "0.999999999 -inf -20.723265865228342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"\n",
      "/opt/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in log\n",
      "  \n",
      "/opt/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "a = expit([-1000, -500, -200, -100, -50, -10, 0, 1, 3, 5, 10, 20, 40, 50])\n",
    "print('a:', a)\n",
    "\n",
    "#Broken\n",
    "print(np.log(1-a))\n",
    "print(np.log(a))\n",
    "\n",
    "for val in a:\n",
    "    newval = min(0.999999999, val)\n",
    "    print(newval, np.log(1-val), np.log(1-newval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doodling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.000045398899218"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(expit(-414.28936167))\n",
    "np.log(expit(-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7200759760208356e-44"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expit(-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5621765008857981"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#When y = 1\n",
    "expit(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.679178699175393"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expit(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7310585786300049"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10 4.539889921682063e-05\n",
      "-9 0.00012340218972322915\n",
      "-8 0.00033540637289577373\n",
      "-7 0.0009114664537742021\n",
      "-6 0.002475685137730443\n",
      "-5 0.006715348489118056\n",
      "-4 0.01814992791780973\n",
      "-3 0.04858735157374202\n",
      "-2 0.12692801104297252\n",
      "-1 0.3132616875182228\n",
      "0 0.6931471805599453\n",
      "1 1.3132616875182228\n",
      "2 2.1269280110429714\n",
      "3 3.048587351573745\n",
      "4 4.01814992791781\n",
      "5 5.006715348489137\n",
      "6 6.002475685137778\n",
      "7 7.000911466453821\n",
      "8 8.000335406373212\n",
      "9 9.000123402189065\n",
      "-10 10.000045398899218\n",
      "-9 9.000123402189724\n",
      "-8 8.000335406372896\n",
      "-7 7.000911466453775\n",
      "-6 6.00247568513773\n",
      "-5 5.006715348489118\n",
      "-4 4.0181499279178094\n",
      "-3 3.048587351573742\n",
      "-2 2.1269280110429727\n",
      "-1 1.3132616875182228\n",
      "0 0.6931471805599453\n",
      "1 0.3132616875182228\n",
      "2 0.12692801104297263\n",
      "3 0.04858735157374191\n",
      "4 0.01814992791780973\n",
      "5 0.006715348489117944\n",
      "6 0.0024756851377303315\n",
      "7 0.0009114664537742021\n",
      "8 0.00033540637289566265\n",
      "9 0.0001234021897233402\n"
     ]
    }
   ],
   "source": [
    "#y=0\n",
    "y=0\n",
    "for pred in range(-10,10):\n",
    "    print(pred, (-y * np.log(expit(pred))) - ( (1-y)*np.log(1-expit(pred)) ) )\n",
    "    \n",
    "y=1\n",
    "for pred in range(-10,10):\n",
    "    print(pred, (-y * np.log(expit(pred))) - ( (1-y)*np.log(1-expit(pred)) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(-20, 20)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(-20,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix A: Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.5, 1.25, 1.118033988749895)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing np.nan____\n",
    "a = [1,2,3,np.nan,4]\n",
    "m = np.nanmean(a)\n",
    "v = np.nanvar(np.array(a))\n",
    "s = np.nanstd(np.array(a))\n",
    "m, v, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    print(expit(i-10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
